{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseaux de neurones LSTM appliqué à la prédiction du turfu de NeoCampus\n",
    "\n",
    "\n",
    "https://icml.cc/Conferences/2002/craft.html\n",
    "Petit résumé :\n",
    " - Describe the representation and organization of the system's knowledge, along with the representation of training data : un graphique du model (keras.utils.plot_model), un head All.csv, un head neolite.csv, un plot\n",
    " - Evaluate the approach to learning, avoiding unsubstantiated or rhetorical claims. If stating that one approach is better than others, include evidence or at least careful arguments to support these claims.\n",
    " - Experiments that systematically vary external resources, such as the number of training cases available for learning, can also contribute important insights into an algorithm's behavior : plot la perf sur le dev set en fonction de $|train set|$\n",
    " - Make sure you label all distinct components of each figure : label des axes, unité s'il y en a une, label des plots, légende et titre\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "## Résumé\n",
    "\n",
    "Nous appliquons un réseau de neurones avec couche LSTM à la prédiction des valeurs futures des capteurs disséminés dans quelques salles du campus de l'UPS, à partir de séries temporelles des valeurs de ces mêmes capteurs. La bibliothèque keras (tensorflow backend) est utilisée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Dans le cadre du M1 DC, nous avons accès aux données des salles équipées de capteurs NeoCampus, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données\n",
    "\n",
    "\n",
    "### Prétraitement\n",
    "\n",
    "#### Données brutes\n",
    "\n",
    "Des capteurs de quatre types (co2, luminosité, humidité et température) sont disposés sur six ilots. Nous disposons des valeurs enregistrées à intervalles variables (entre une seconde et une minute selon le capteur).\n",
    "\n",
    "|type|room|value|date|unit|ilot|\n",
    "|---|---|---|---|---|---|\n",
    "|temperature|u4/302/temperature/ilot1|22.93|2017-09-11T12:53:14.745366|celsius|ilot1|\n",
    "|temperature|u4/302/temperature/ilot2|24.16|2017-09-11T12:53:14.767362|celsius|ilot2|\n",
    "|co2|u4/302/co2/ilot1|357|2017-09-11T12:53:14.794131|ppm|ilot1|\n",
    "|temperature|u4/302/temperature/ilot3|24.36|2017-09-11T12:53:14.797038|celsius|ilot3|\n",
    "|co2|u4/302/co2/ilot2|361|2017-09-11T12:53:14.818348|ppm|ilot2|\n",
    "\n",
    "*Table 1 : Données brutes*\n",
    "\n",
    "#### Prétraitement - phase 1\n",
    "\n",
    "Les valeurs sont sélectionnées par type (ici la luminosité), agrégées par moyenne sur un interval donné (ici 15 minutes), et associées à leur valeur de confort\n",
    "\n",
    "|timestamp|lum|confort|\n",
    "|---|---|---|\n",
    "|1254272|839.35|5|\n",
    "|1254273|867.5833333333334|5|\n",
    "|1254274|791.0666666666667|5|\n",
    "|1254275|466.53333333333336|2|\n",
    "|1254276|698.5932203389831|5|\n",
    "\n",
    "*Table 2 : Luminosité de l'ilot1, moyenne sur 15 minutes*\n",
    "\n",
    "#### Prétraitement - phase 2\n",
    "\n",
    "Les valeurs sont regroupées en séries temporelles, puis normalisées.\n",
    "Soient :\n",
    "\n",
    "  - $v_i$ la valeur d'un capteur d'un type donné à l'instant $i$\n",
    "  - $w$ la taille de la fenêtre\n",
    "  - $k$ l'avance (on prédit $k$ instants après)\n",
    "\n",
    "Nous formons un vecteur $(v_1, v_2, ..., v_w)$ que nous étiquetons avec la valeur moyenne de la $k$-ième prochaine fenêtre $\\sum_{i=1}^{k}{v_{w k+i}} \\over w$ :\n",
    "\n",
    "| $v_1$ | $v_1$ | $v_1$ | $v_1$ | $\\sum_{i=1}^{k}{v_{w k+i}} / w$ |\n",
    "|---|---|---|---|---|\n",
    "|361.11666666666673|351.8|334.31666666666666|237.56666666666663|235.1125|\n",
    "|236.4|234.11864406779662|236.0|233.36666666666667|256.45296610169487|\n",
    "|234.55|237.38333333333333|234.5|234.01666666666668|737.2541666666667|\n",
    "|234.16666666666663|235.51666666666668|237.41666666666663|318.7118644067797|378.575|\n",
    "|827.5166666666668|1219.5333333333333|531.4166666666666|370.55|351.275|\n",
    "\n",
    "*Table 3 : Fenêtre temporelle de 4 valeurs, prédiction à i+8*\n",
    "\n",
    "\n",
    "**Après interpolation, on perd la relation de moyenne**\n",
    "\n",
    "\n",
    "| $v_1$ | $v_1$ | $v_1$ | $v_1$ | $\\sum_{i=1}^{k}{v_{w k+i}} / w$ |\n",
    "|---|---|---|---|---|\n",
    "|0.13202776|0.12696186|0.11745537|0.06484798|0.09021222322482127|\n",
    "|0.06421361|0.06297313|0.06399611|0.06256424|0.10701879027823007|\n",
    "|0.06320768|0.06474829|0.06318049|0.06291768|0.4856711392076145|\n",
    "|0.06299924|0.0637333|0.06476641|0.10897033|0.20319532839271504|\n",
    "|0.38563077|0.59878815|0.22462766|0.13715709|0.18169536309806658|\n",
    "\n",
    "*Table 4 : Fenêtre temporelle de 4 valeurs normalisées, prédiction à i+8*\n",
    "\n",
    "\n",
    "**Après interpolation inverse, on ne la retrouve pas !**\n",
    "\n",
    "\n",
    "| $v_1$ | $v_1$ | $v_1$ | $v_1$ | $\\sum_{i=1}^{k}{v_{w k+i}} / w$ |\n",
    "|---|---|---|---|---|\n",
    "|288.20859275|281.77607043|269.70502228|202.905752|235.1125|\n",
    "|202.10024831|200.52512778|201.82407562|200.00593872|256.45296610169487|\n",
    "|200.82294961|202.77917285|200.78842802|200.45471935|737.2541666666667|\n",
    "|200.55828411|201.49036695|202.80218724|258.93097159|378.575|\n",
    "|610.22595354|880.88670051|405.78911707|294.72166544|351.2749999999999|\n",
    "\n",
    "*Table 5 : Fenêtre temporelle de 4 valeurs dé-normalisées, prédiction à i+8*\n",
    "\n",
    "\n",
    "**C'est donc un problème, non ?**\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "Données brutes, prétraitement, visualisations/exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisations\n",
    "\n",
    "#### Distributions\n",
    "\n",
    "<table style=\"border: '0'\">\n",
    "        <col width=\"70%\">\n",
    "        <col>\n",
    "        <!--<tr style=\"background: None\"><td></td><td></td></td>-->\n",
    "        <tr> \n",
    "            <td> <img src=\"images/distribution_time.png\"> </td>\n",
    "            <td>\n",
    "                <p>La présence de longues périodes sans données recueillies (ou très peu) demandera d'être prise en compte lors de la création des séries temporelles, sans quoi certaines n'auront pas le nombre requis de mesures.</p>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td> <img src=\"images/distributions_sensors.png\"> </td>\n",
    "            <td>\n",
    "                <p>Ici, on peut observer la distribution des différentes colonnes des données : certains capteurs ont une large plage de valeurs possibles  distribuées de manière relativement uniforme (humidité, température), d'autres sont disposées sur des modes avec quelques occurences des valeurs non modales (co2, luminosité).\n",
    "On observe que le confort ne descend que très rarement en dessous de 2 : soit la fonction de confort est mal paramétrée, soit les conditions environnementales des salles ne sont jamais horribles (la seconde hypothèse semble plus probable).</p>\n",
    "            </td>\n",
    "        </tr>\n",
    "</table>\n",
    "\n",
    "#### Corrélations\n",
    "\n",
    "<table>\n",
    "        <col width=\"70%\">\n",
    "        <col>\n",
    "        <!--<tr style=\"background: None\"><td></td><td></td></td>-->\n",
    "        <tr> \n",
    "            <td> <img src=\"images/correlations_heatmap.png\"> </td>\n",
    "            <td>\n",
    "                <p>Cette matrice présente la corrélation entre chaque capteur. On y observe le fonctionnement de la fonction de confort : le principal facteur est la température, suivie de la luminosité, puis de l'humidité et du co2. On remarque de relativement fortes corrélations entre luminosité et température (le soleil serait-il le facteur commun ?), et entre co2 et température/luminosité (le fait que les humains sont diurnes serait-il le facteur commun ?). L'humidité ne semble pas corrélée à quoi que ce soit de manière notable : peut-être pourrait on la retirer sans trop de pertes de performances.\n",
    "On déduit de cette matrice que l'on obtiendra de biens meilleures prédictions avec tous les capteurs qu'avec un seul. (EST-CE RAISONNABLE COMME DEDUCTION ??)</p>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td> <img src=\"images/autocorrelation_lum.png\"> </td>\n",
    "            <td>\n",
    "                <p>On remarque très bien la présence d'un cycle de 24h dans l'autocorrélation du capteur de luminosité. Cela permet de confirmer que les valeurs des capteurs dépendent du moment de la journée, et sont prédictibles à partir des valeurs antérieures (pas complétement, sinon on aurait une autocorrélation de 1). Cette autocorrélation diminue avec l'augmentation du délai, à cause de l'influence de paramètres externes (il est possible que demain soit plus nuageux qu'hier...).\n",
    "La luminosité présente l'autocorrélation la plus forte, mais tous les capteurs sont un minimum autocorrélés (sur des multiples de 24h).probable).</p>\n",
    "            </td>\n",
    "        </tr>\n",
    "</table>\n",
    "\n",
    "#### k-means\n",
    "\n",
    "<table>\n",
    "        <col width=\"70%\">\n",
    "        <col>\n",
    "        <!--<tr style=\"background: None\"><td></td><td></td></td>-->\n",
    "        <tr> \n",
    "            <td> <img src=\"images/kmeans_co2.png\"> </td>\n",
    "            <td>\n",
    "                <p>L'algorithme de clustering k-means peut également être appliquée sur des séries temporelles. Les clusters seront les séries \"moyennes/types\" du jeu de données.\n",
    "Les lignes rouges représentent les clusters et les lignes noires (ou tâches noires en fond) les observations assignées au cluster. L'opacité des observations assignées montrent leur nombre.</p>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td> <img src=\"images/kmeans_confort.png\"> </td>\n",
    "            <td>\n",
    "                <p>On voit bien que les périodes de changement (clusters 1 et 2) sont moins fréquentes que les périodes stables (cluster 3). Il est important de prendre cette répartition en compte afin de ne pas obtenir un modèle prédisant des séries stables (qui pourrait se voir attribuer une bonne performance selon la métrique dûe à leur forte proportion dans les données).</p>\n",
    "            </td>\n",
    "        </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "#### Décomposition saisonale\n",
    "\n",
    "<table>\n",
    "        <col width=\"70%\">\n",
    "        <col>\n",
    "        <tr> \n",
    "            <td> <img src=\"images/decomposition_seasonal_temp.png\"> </td>\n",
    "            <td>\n",
    "                <p>Il est possible de décomposer une série temporelle. Nous avons utilisé une décomposition saisonale naïve (statsmodels.api.tsa.seasonal_decompose()) qui permet d'obtenir les composantes \"trend\" (tendance), \"seasonal\" (saisonale/périodique) et \"residual\" (résidus). En combinant ces deux composantes, on obtient la courbe d'origine, aux résidus près (plus il y a de résidus, moins la décomposition permet de reproduire la série originel : la série est bruitée (ou notre modèle inadaptée..)).</p>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td> <img src=\"images/decomposition_predictions_temp.png\"> </td>\n",
    "            <td>\n",
    "                <p>Ce graphique présente le modèle obtenu par décomposition sur une période appliquée à cette même période (en vert), puis aux restes des données (en rouge). On voit très bien que le comportement de la courbe n'est pas le même du tout entre ces deux périodes. Il est nécessaire de prendre en compte ces différences dans la distribution des cibles lors de l'entraînement d'un modèle (sinon on a un modèle qui prédit très bien la semaine 38 de l'année 2017, mais rien d'autre).\n",
    "Ici, le modèle se trompe complètement, mais pour certains capteurs (luminosité notament), la composante saisonale reste la même quelque soit la période de l'année.</p>\n",
    "            </td>\n",
    "        </tr>\n",
    "</table>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle\n",
    "\n",
    "Description du modèle, pourquoi (ou le pourquoi sera dans l'intro ?), processus d'entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résultats\n",
    "\n",
    "Nous effectuons plusieurs tests pour estimer notre modèle, en le comparant avec la régression linéaire classique de scikit-learn.\n",
    "\n",
    "On teste sur les données de l'ilot1, pour chaque type de capteur (pas les mêmes allures de courbes), pour les configurations suivantes : \n",
    "\n",
    " - Fenêtre de taille 2, prédiction de la fenêtre suivante\n",
    " - Fenêtre de taille 16, prédiction de la 4ème fenêtre suivante\n",
    " - Fenêtre de taille 32, prédiction de la 16ème fenêtre suivante\n",
    "\n",
    "Lorsqu'on prédit loin dans l'avenir, aucune prédiction intermédiaire n'a été prévue.\n",
    "\n",
    "On a mesuré plusieurs métriques\n",
    "\n",
    " - Mean absolute error et mean squared error : ça montre l'écart entre les prévisions et la réalité. La seconde pénalise les très mauvaises prédictions. C'est une mesure de régression, faite sur la valeur prédite du capteur.\n",
    " - Accuracy f-measure jaccard : les trois donnent exactement le même résultat, je ne sais pas pourquoi :-( C'est une métrique de classification calculée sur le score de confort, recalculé depuis la valeur prédite du capteur.\n",
    " - Distance au sens de la DTW : non calculée car *très très* long. \n",
    "\n",
    "D'une façon générale, les résultats sont très proches entre le modèle super-balèze long à entraîner et la régression qui prend moins d'une seconde. Même si le modèle s'avère *un tout petit peu* meilleur.\n",
    "\n",
    "Mesures de MAE, MSE et Accuracy pour les différentes combinaisons de test : les mêmes erreurs sur les mêmes tests !\n",
    "\n",
    "\n",
    "| Mean average error | Mean squared error | Accuracy |\n",
    "|---|---|---|\n",
    "| ![mae.png](images/evaluation/mae.png) | ![mse.png](images/evaluation/mse.png) | ![accu.png](images/evaluation/accu.png) |\n",
    "\n",
    "\n",
    "\n",
    "Par ailleurs j'ai reservé quelques dizaines de points pour la visualisation de prédiction alignées. Je ne sais pas si c'est très utile ici, mais moi ça m'a bien parlé : c'est facilement interprétable comme on dit.\n",
    "\n",
    "|Jeu de test|MSE|Précision|Visualisation LSTM64-ReLU16-Sigm1|Visualisation régression linéaire|\n",
    "|---|---|---|---|---|\n",
    "|ilot1.temp.300.2.1| Faible 0.005 | Élevée 0.93 | ![contiguous.ilot1.temp.300.2.1.LSTM64-ReLU16-Sigm1.png](images/evaluation/contiguous.ilot1.temp.300.2.1.LSTM64-ReLU16-Sigm1.png) | ![contiguous.ilot1.temp.300.2.1.LinearRegression.png](images/evaluation/contiguous.ilot1.temp.300.2.1.LinearRegression.png) |\n",
    "|ilot1.co2.3600.16.4 | Élevée 0.09 | Élevée 0.92 | ![contiguous.ilot1.co2.3600.16.4.LSTM64-ReLU16-Sigm1.png](images/evaluation/contiguous.ilot1.co2.3600.16.4.LSTM64-ReLU16-Sigm1.png) | ![contiguous.ilot1.co2.3600.16.4.LinearRegression.png](images/evaluation/contiguous.ilot1.co2.3600.16.4.LinearRegression.png) |\n",
    "|ilot1.temp.3600.32.16| Élevée 0.1 | Faible 0.22 | ![contiguous.ilot1.temp.3600.32.16.LSTM64-ReLU16-Sigm1.png](images/evaluation/contiguous.ilot1.temp.3600.32.16.LSTM64-ReLU16-Sigm1.png) | ![contiguous.ilot1.temp.3600.32.16.LinearRegression.png](images/evaluation/contiguous.ilot1.temp.3600.32.16.LinearRegression.png) |\n",
    "\n",
    "Donc finalement on peut conclure que : \n",
    "\n",
    " - Le modèle fait quelque chose de très comparable à la régression linéaire\n",
    " - La MSE et la MAE mesurent la même chose, mais diffèrent de la précision. En effet, on discrétise avec la fonction de confort, qui n'est pas homogène : les erreurs ne sont pas toutes atténuées de la même façon.\n",
    " - Le modèle, comme la régression, sont efficaces sur les prédictions à un quart d'heure, mais moins sur les prédictions à une heure. Encore moins sur celles à 4, et à 16. C'est parce qu'ils ont tendance à prédire en retard, et que ce retard est moins grave sur 15 minutes. On pourrait vérifier cette théorie en prédisant sur un intervalle qui matche avec la saisonnalité des données (24 heures).\n",
    " \n",
    " \n",
    "\n",
    "métriques et méthodes d'évaluation, plots des prédictions, recette du kebab vegan, description des résultats (la mse monte quand x, on a trouvé un optimal, ça marche bien à x point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse\n",
    "\n",
    "Des explications plus fines que ce qui est directement visible dans les résultats : ça marche bien parce que..., ça marche mal parce que \n",
    "\n",
    "Ce qu'on va essayer la prochaine fois (ou alors dans la conclusion si c'est court ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Nous avons fait X, ça a donné Y mais aussi Z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
